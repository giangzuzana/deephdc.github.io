<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>DEEP Open Catalog - library/tensorflow</title><link href="https://marketplace.deep-hybrid-datacloud.eu/" rel="alternate"></link><link href="https://marketplace.deep-hybrid-datacloud.eu/feeds/library/tensorflow.atom.xml" rel="self"></link><id>https://marketplace.deep-hybrid-datacloud.eu/</id><updated>2018-11-26T00:00:00+01:00</updated><entry><title>DEEP OC Image Classification (Tensorflow)</title><link href="https://marketplace.deep-hybrid-datacloud.eu/models/deep-oc-image-classification-tensorflow.html" rel="alternate"></link><published>2018-11-15T00:00:00+01:00</published><updated>2018-11-15T00:00:00+01:00</updated><author><name>DEEP-Hybrid-DataCloud Consortium</name></author><id>tag:marketplace.deep-hybrid-datacloud.eu,2018-11-15:/models/deep-oc-image-classification-tensorflow.html</id><summary type="html">&lt;p&gt;A tool to train an image classifier on your data&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://jenkins.indigo-datacloud.eu:8080/job/Pipeline-as-code/job/DEEP-OC-org/job/image-classification-tf/job/master/"&gt;&lt;img alt="Build Status" src="https://jenkins.indigo-datacloud.eu:8080/buildStatus/icon?job=Pipeline-as-code/DEEP-OC-org/image-classification-tf/master"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The deep learning revolution has brought significant advances in a number of
fields [1], primarily linked to image and speech recognition. The
standardization of image classification tasks like the &lt;a href="http://www.image-net.org/challenges/LSVRC/"&gt;ImageNet Large Scale
Visual Recognition Challenge&lt;/a&gt; [2]
has resulted in a reliable way to compare top performing architectures.&lt;/p&gt;
&lt;p&gt;This Docker container contains the tools to train an image classifier on your custom
dataset. It is a highly customizable tool  that let's you choose between tens of different &lt;a href="https://github.com/keras-team/keras-applications"&gt;top performing
arquitectures&lt;/a&gt; and training parameters.&lt;/p&gt;
&lt;h3&gt;References&lt;/h3&gt;
&lt;p&gt;[1]: Yann LeCun, Yoshua Bengio, and Geofrey Hinton. &lt;a href="https://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf"&gt;Deep learning&lt;/a&gt;. Nature, 521(7553):436–444, may 2015.&lt;/p&gt;
&lt;p&gt;[2]: Olga Russakovsky et al. &lt;a href="https://arxiv.org/abs/1409.0575"&gt;ImageNet Large Scale Visual Recognition Challenge&lt;/a&gt;. International Journal of Computer Vision (IJCV), 115(3):211–252, 2015.&lt;/p&gt;</content></entry><entry><title>DEEP OC dogs breed determination</title><link href="https://marketplace.deep-hybrid-datacloud.eu/models/deep-oc-dogs-breed-determination.html" rel="alternate"></link><published>2018-07-03T10:20:00+02:00</published><updated>2018-11-26T00:00:00+01:00</updated><author><name>DEEP-Hybrid-DataCloud Consortium</name></author><id>tag:marketplace.deep-hybrid-datacloud.eu,2018-07-03:/models/deep-oc-dogs-breed-determination.html</id><summary type="html">&lt;p&gt;A toy example to identify Dog's breed.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://jenkins.indigo-datacloud.eu:8080/job/Pipeline-as-code/job/DEEP-OC-org/job/dogs_breed_det/job/master/"&gt;&lt;img alt="Build Status" src="https://jenkins.indigo-datacloud.eu:8080/buildStatus/icon?job=Pipeline-as-code/DEEP-OC-org/dogs_breed_det/master"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A toy example to identify Dog's breed, "Dogs breed detector", as example for &lt;a href="https://github.com/indigo-dc/DEEPaaS"&gt;DEEPaaS API&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Dogs breed detector is originally forked from &lt;a href="https://github.com/udacity/dog-project"&gt;udacity/dogs-project&lt;/a&gt;, dataset comes from &lt;a href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip"&gt;dog dataset&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The project applies Transfer learning for dog's breed identification, implemented with Tensorflow and Keras:&lt;/p&gt;
&lt;p&gt;From a pre-trained model (VGG16 | VGG19 | Resnet50 | InceptionV3 | Xception) the last layer is removed, then a new FC classification layer is added, which is trained. All images first pass through the pre-trained network and converted into the tensor with the shape of the 'before-last' layer of the pre-trained network, into so-called 'bottleneck_features'. These bottleneck_features are used then as input for the FC classification network.&lt;/p&gt;</content></entry></feed>